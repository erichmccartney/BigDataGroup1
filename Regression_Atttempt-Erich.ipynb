{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree - Regression\n",
    "\n",
    "We will predict the price (`price` column) of an AirBNB listing in Boston given a number of features about the listing.\n",
    "\n",
    "**Therefore, our unit of analysis is an AIRBNB LISTING**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PropertyType</th>\n",
       "      <th>SiteAddress</th>\n",
       "      <th>SiteCity</th>\n",
       "      <th>SiteZip</th>\n",
       "      <th>Acreage</th>\n",
       "      <th>Homestead</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>TotalNumBuildings</th>\n",
       "      <th>TotalUnits</th>\n",
       "      <th>TotalStories</th>\n",
       "      <th>...</th>\n",
       "      <th>TotalBuildingValue</th>\n",
       "      <th>TotalExtraFeaturesValue</th>\n",
       "      <th>TotalHeatedAreaSqFt</th>\n",
       "      <th>JustValue</th>\n",
       "      <th>AssessedValue</th>\n",
       "      <th>TaxableValue</th>\n",
       "      <th>LastSaleDate</th>\n",
       "      <th>LastSalePrice</th>\n",
       "      <th>VacantImproved</th>\n",
       "      <th>Qualified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SINGLE FAMILY</td>\n",
       "      <td>8302 LUTZ LAKE FERN RD</td>\n",
       "      <td>ODESSA</td>\n",
       "      <td>33556</td>\n",
       "      <td>0.97</td>\n",
       "      <td>No</td>\n",
       "      <td>E Lutz Lake Fern, W of Vets Xway</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>128296</td>\n",
       "      <td>2548</td>\n",
       "      <td>1094</td>\n",
       "      <td>264085</td>\n",
       "      <td>248933</td>\n",
       "      <td>248933</td>\n",
       "      <td>2020-02-16</td>\n",
       "      <td>100</td>\n",
       "      <td>Improved</td>\n",
       "      <td>Unqualified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SINGLE FAMILY</td>\n",
       "      <td>8304 LUTZ LAKE FERN RD</td>\n",
       "      <td>ODESSA</td>\n",
       "      <td>33556</td>\n",
       "      <td>1.47</td>\n",
       "      <td>Yes</td>\n",
       "      <td>E Lutz Lake Fern, W of Vets Xway</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>263121</td>\n",
       "      <td>40759</td>\n",
       "      <td>2737</td>\n",
       "      <td>473506</td>\n",
       "      <td>268658</td>\n",
       "      <td>218658</td>\n",
       "      <td>2001-05-14</td>\n",
       "      <td>195000</td>\n",
       "      <td>Improved</td>\n",
       "      <td>Unqualified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SINGLE FAMILY</td>\n",
       "      <td>19146 HUCKAVALLE RD</td>\n",
       "      <td>ODESSA</td>\n",
       "      <td>33556</td>\n",
       "      <td>5.50</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Northwest Corner of Hillsborough County</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>107433</td>\n",
       "      <td>45940</td>\n",
       "      <td>1555</td>\n",
       "      <td>417449</td>\n",
       "      <td>400551</td>\n",
       "      <td>350551</td>\n",
       "      <td>2018-01-25</td>\n",
       "      <td>425000</td>\n",
       "      <td>Improved</td>\n",
       "      <td>Qualified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SINGLE FAMILY</td>\n",
       "      <td>19108 RUSTIC WOODS TRL</td>\n",
       "      <td>ODESSA</td>\n",
       "      <td>33556</td>\n",
       "      <td>4.71</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Northwest Corner of Hillsborough County</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>392657</td>\n",
       "      <td>57535</td>\n",
       "      <td>5376</td>\n",
       "      <td>680454</td>\n",
       "      <td>403161</td>\n",
       "      <td>348161</td>\n",
       "      <td>2004-11-10</td>\n",
       "      <td>395000</td>\n",
       "      <td>Improved</td>\n",
       "      <td>Qualified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SINGLE FAMILY</td>\n",
       "      <td>19115 HUCKAVALLE RD</td>\n",
       "      <td>ODESSA</td>\n",
       "      <td>33556</td>\n",
       "      <td>4.88</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Northwest Corner of Hillsborough County</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>266616</td>\n",
       "      <td>59064</td>\n",
       "      <td>3228</td>\n",
       "      <td>573680</td>\n",
       "      <td>288391</td>\n",
       "      <td>238391</td>\n",
       "      <td>2005-03-29</td>\n",
       "      <td>500000</td>\n",
       "      <td>Improved</td>\n",
       "      <td>Unqualified</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    PropertyType             SiteAddress SiteCity SiteZip  Acreage Homestead  \\\n",
       "0  SINGLE FAMILY  8302 LUTZ LAKE FERN RD   ODESSA   33556     0.97        No   \n",
       "1  SINGLE FAMILY  8304 LUTZ LAKE FERN RD   ODESSA   33556     1.47       Yes   \n",
       "2  SINGLE FAMILY     19146 HUCKAVALLE RD   ODESSA   33556     5.50       Yes   \n",
       "3  SINGLE FAMILY  19108 RUSTIC WOODS TRL   ODESSA   33556     4.71       Yes   \n",
       "4  SINGLE FAMILY     19115 HUCKAVALLE RD   ODESSA   33556     4.88       Yes   \n",
       "\n",
       "                              Neighborhood  TotalNumBuildings  TotalUnits  \\\n",
       "0         E Lutz Lake Fern, W of Vets Xway                  1           1   \n",
       "1         E Lutz Lake Fern, W of Vets Xway                  1           1   \n",
       "2  Northwest Corner of Hillsborough County                  1           1   \n",
       "3  Northwest Corner of Hillsborough County                  1           1   \n",
       "4  Northwest Corner of Hillsborough County                  1           1   \n",
       "\n",
       "   TotalStories  ...  TotalBuildingValue  TotalExtraFeaturesValue  \\\n",
       "0           1.0  ...              128296                     2548   \n",
       "1           1.0  ...              263121                    40759   \n",
       "2           1.0  ...              107433                    45940   \n",
       "3           2.0  ...              392657                    57535   \n",
       "4           1.0  ...              266616                    59064   \n",
       "\n",
       "   TotalHeatedAreaSqFt  JustValue  AssessedValue  TaxableValue  LastSaleDate  \\\n",
       "0                 1094     264085         248933        248933    2020-02-16   \n",
       "1                 2737     473506         268658        218658    2001-05-14   \n",
       "2                 1555     417449         400551        350551    2018-01-25   \n",
       "3                 5376     680454         403161        348161    2004-11-10   \n",
       "4                 3228     573680         288391        238391    2005-03-29   \n",
       "\n",
       "   LastSalePrice  VacantImproved    Qualified  \n",
       "0            100        Improved  Unqualified  \n",
       "1         195000        Improved  Unqualified  \n",
       "2         425000        Improved    Qualified  \n",
       "3         395000        Improved    Qualified  \n",
       "4         500000        Improved  Unqualified  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We will predict the \"price\" value in the data set:\n",
    "\n",
    "hills = pd.read_csv(\"HillsboroughCountyData.csv\")\n",
    "hills.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_set, test_set = train_test_split(hills, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Be careful: we haven't seperated the target column yet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PropertyType                  0\n",
       "SiteAddress                  18\n",
       "SiteCity                      2\n",
       "SiteZip                      10\n",
       "Acreage                       0\n",
       "Homestead                     0\n",
       "Neighborhood                  0\n",
       "TotalNumBuildings             0\n",
       "TotalUnits                    0\n",
       "TotalStories                  0\n",
       "TotalBedrooms                 0\n",
       "TotalBathrooms                0\n",
       "YearBuilt                     0\n",
       "TotalLandValue                0\n",
       "TotalBuildingValue            0\n",
       "TotalExtraFeaturesValue       0\n",
       "TotalHeatedAreaSqFt           0\n",
       "JustValue                     0\n",
       "AssessedValue                 0\n",
       "TaxableValue                  0\n",
       "LastSaleDate                464\n",
       "LastSalePrice                 0\n",
       "VacantImproved             1839\n",
       "Qualified                   445\n",
       "dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PropertyType                 0\n",
       "SiteAddress                  7\n",
       "SiteCity                     1\n",
       "SiteZip                      2\n",
       "Acreage                      0\n",
       "Homestead                    0\n",
       "Neighborhood                 0\n",
       "TotalNumBuildings            0\n",
       "TotalUnits                   0\n",
       "TotalStories                 0\n",
       "TotalBedrooms                0\n",
       "TotalBathrooms               0\n",
       "YearBuilt                    0\n",
       "TotalLandValue               0\n",
       "TotalBuildingValue           0\n",
       "TotalExtraFeaturesValue      0\n",
       "TotalHeatedAreaSqFt          0\n",
       "JustValue                    0\n",
       "AssessedValue                0\n",
       "TaxableValue                 0\n",
       "LastSaleDate               206\n",
       "LastSalePrice                0\n",
       "VacantImproved             785\n",
       "Qualified                  199\n",
       "dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.preprocessing import FunctionTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop the variables we can't use in this tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can't use the following columns in this tutorial, because they are for classification tasks\n",
    "\n",
    "train = train_set.drop([], axis=1)\n",
    "test = test_set.drop([], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate the target variable (we don't want to transform it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train[['JustValue']]\n",
    "test_y = test[['JustValue']]\n",
    "\n",
    "train_inputs = train.drop(['JustValue'], axis=1)\n",
    "test_inputs = test.drop(['JustValue'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering: Let's derive a new column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Formula: `reviews per day` = `number of reviews` / `number_days_btw_first_last_review`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_col(df):\n",
    "    \n",
    "    #Create a copy so that we don't overwrite the existing dataframe\n",
    "    df1 = df.copy()\n",
    "\n",
    "    # Use the formula, though fill in 0s when the value is 0/0 (because 0/0 generates \"nan\" values)\n",
    "    df1['reviews_per_day'] = (df1['number_of_reviews']/df1['number_days_btw_first_last_review']).fillna(0)\n",
    "\n",
    "    # Replace the infinity values with 1 (because a value divided by 0 generates infinity)\n",
    "    df1['reviews_per_day'].replace(np.inf, 1, inplace=True)\n",
    "\n",
    "    return df1[['reviews_per_day']]\n",
    "    # You can use this to check whether the calculation is made correctly:\n",
    "    #return df1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's test the new function:\n",
    "\n",
    "# Send the train set to the function we created\n",
    "new_col(train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Identify the numerical and categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PropertyType                object\n",
       "SiteAddress                 object\n",
       "SiteCity                    object\n",
       "SiteZip                     object\n",
       "Acreage                    float64\n",
       "Homestead                   object\n",
       "Neighborhood                object\n",
       "TotalNumBuildings            int64\n",
       "TotalUnits                   int64\n",
       "TotalStories               float64\n",
       "TotalBedrooms              float64\n",
       "TotalBathrooms             float64\n",
       "YearBuilt                    int64\n",
       "TotalLandValue               int64\n",
       "TotalBuildingValue           int64\n",
       "TotalExtraFeaturesValue      int64\n",
       "TotalHeatedAreaSqFt          int64\n",
       "AssessedValue                int64\n",
       "TaxableValue                 int64\n",
       "LastSaleDate                object\n",
       "LastSalePrice                int64\n",
       "VacantImproved              object\n",
       "Qualified                   object\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_inputs.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**At this stage, you can manually identify numeric, binary, and categorical columns as follows:**\n",
    "\n",
    "`numeric_columns = ['latitude', 'longitude', 'accommodates', 'bathrooms', 'bedrooms', 'beds', 'Number of amenities', 'guests_included', 'price_per_extra_person', 'minimum_nights', 'number_of_reviews', 'number_days_btw_first_last_review', 'review_scores_rating']`\n",
    " \n",
    " `binary_columns = ['host_is_superhost', 'host_identity_verified']`\n",
    " \n",
    " `categorical_columns = ['neighbourhood_cleansed', 'property_type', 'room_type', 'bed_type', 'cancellation_policy']`\n",
    " \n",
    "<br>\n",
    " \n",
    "**If you do not want to manually type these, you can do the below tricks:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the numerical columns\n",
    "numeric_columns = train_inputs.select_dtypes(include=[np.number]).columns.to_list()\n",
    "\n",
    "# Identify the categorical columns\n",
    "categorical_columns = train_inputs.select_dtypes('object').columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the binary columns so we can pass them through without transforming\n",
    "binary_columns = ['Homestead', 'Qualified']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Be careful: numerical columns already includes the binary columns,\n",
    "# So, we need to remove the binary columns from numerical columns.\n",
    "\n",
    "for col in binary_columns:\n",
    "    categorical_columns.remove(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Homestead', 'Qualified']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Acreage',\n",
       " 'TotalNumBuildings',\n",
       " 'TotalUnits',\n",
       " 'TotalStories',\n",
       " 'TotalBedrooms',\n",
       " 'TotalBathrooms',\n",
       " 'YearBuilt',\n",
       " 'TotalLandValue',\n",
       " 'TotalBuildingValue',\n",
       " 'TotalExtraFeaturesValue',\n",
       " 'TotalHeatedAreaSqFt',\n",
       " 'AssessedValue',\n",
       " 'TaxableValue',\n",
       " 'LastSalePrice']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PropertyType',\n",
       " 'SiteAddress',\n",
       " 'SiteCity',\n",
       " 'SiteZip',\n",
       " 'Neighborhood',\n",
       " 'LastSaleDate',\n",
       " 'VacantImproved']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_eng_columns = ['number_of_reviews', 'number_days_btw_first_last_review']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_transformer = Pipeline(steps=[\n",
    "                ('imputer', SimpleImputer(strategy='median')),\n",
    "                ('scaler', StandardScaler())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='unknown')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'new_col' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-5d04265ad852>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m my_new_column = Pipeline(steps=[('my_new_column', FunctionTransformer(new_col)),\n\u001b[0m\u001b[0;32m      2\u001b[0m                                ('scaler', StandardScaler())])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'new_col' is not defined"
     ]
    }
   ],
   "source": [
    "my_new_column = Pipeline(steps=[('my_new_column', FunctionTransformer(new_col)),\n",
    "                               ('scaler', StandardScaler())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer([\n",
    "        ('num', numeric_transformer, numeric_columns),\n",
    "        ('cat', categorical_transformer, categorical_columns),\n",
    "        ('binary', binary_transformer, binary_columns)],\n",
    "        #('trans', my_new_column, feat_eng_columns)],\n",
    "        remainder='passthrough')\n",
    "\n",
    "#passtrough is an optional step. You don't have to use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PropertyType                  0\n",
       "SiteAddress                  18\n",
       "SiteCity                      2\n",
       "SiteZip                      10\n",
       "Acreage                       0\n",
       "Homestead                     0\n",
       "Neighborhood                  0\n",
       "TotalNumBuildings             0\n",
       "TotalUnits                    0\n",
       "TotalStories                  0\n",
       "TotalBedrooms                 0\n",
       "TotalBathrooms                0\n",
       "YearBuilt                     0\n",
       "TotalLandValue                0\n",
       "TotalBuildingValue            0\n",
       "TotalExtraFeaturesValue       0\n",
       "TotalHeatedAreaSqFt           0\n",
       "JustValue                     0\n",
       "AssessedValue                 0\n",
       "TaxableValue                  0\n",
       "LastSaleDate                464\n",
       "LastSalePrice                 0\n",
       "VacantImproved             1839\n",
       "Qualified                   445\n",
       "dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform: fit_transform() for TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "For a sparse output, all columns should be a numeric or convertible to a numeric.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\u001b[0m in \u001b[0;36m_hstack\u001b[1;34m(self, Xs)\u001b[0m\n\u001b[0;32m    588\u001b[0m                 \u001b[1;31m# dtype conversion if necessary.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 589\u001b[1;33m                 converted_Xs = [check_array(X,\n\u001b[0m\u001b[0;32m    590\u001b[0m                                             \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    588\u001b[0m                 \u001b[1;31m# dtype conversion if necessary.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 589\u001b[1;33m                 converted_Xs = [check_array(X,\n\u001b[0m\u001b[0;32m    590\u001b[0m                                             \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    615\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 616\u001b[1;33m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    617\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     82\u001b[0m     \"\"\"\n\u001b[1;32m---> 83\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'No'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-7fe0e704113a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Fit and transform the train data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocessor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtrain_x\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    528\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    529\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 530\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_hstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    531\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    532\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\u001b[0m in \u001b[0;36m_hstack\u001b[1;34m(self, Xs)\u001b[0m\n\u001b[0;32m    592\u001b[0m                                 for X in Xs]\n\u001b[0;32m    593\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 594\u001b[1;33m                 raise ValueError(\n\u001b[0m\u001b[0;32m    595\u001b[0m                     \u001b[1;34m\"For a sparse output, all columns should \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    596\u001b[0m                     \u001b[1;34m\"be a numeric or convertible to a numeric.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: For a sparse output, all columns should be a numeric or convertible to a numeric."
     ]
    }
   ],
   "source": [
    "#Fit and transform the train data\n",
    "train_x = preprocessor.fit_transform(train_inputs)\n",
    "\n",
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tranform: transform() for TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the test data\n",
    "test_x = preprocessor.transform(test_inputs)\n",
    "\n",
    "test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate the baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First find the average value of the target\n",
    "\n",
    "mean_value = np.mean(train_y['price'])\n",
    "\n",
    "mean_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict all values as the mean\n",
    "\n",
    "baseline_pred = np.repeat(mean_value, len(test_y))\n",
    "\n",
    "baseline_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_mse = mean_squared_error(test_y, baseline_pred)\n",
    "\n",
    "baseline_rmse = np.sqrt(baseline_mse)\n",
    "\n",
    "print('Baseline RMSE: {}' .format(baseline_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y['price']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model\n",
    "\n",
    "Do NOT train a DecisionTreeRegressor() without any parameters. It OVERFITS. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tree_reg = DecisionTreeRegressor(min_samples_leaf = 10) # remove parameter to have un-restricted learning\n",
    "\n",
    "tree_reg.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train RMSE\n",
    "train_pred = tree_reg.predict(train_x)\n",
    "\n",
    "train_mse = mean_squared_error(train_y, train_pred)\n",
    "\n",
    "train_rmse = np.sqrt(train_mse)\n",
    "\n",
    "print('Train RMSE: {}' .format(train_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test RMSE\n",
    "test_pred = tree_reg.predict(test_x)\n",
    "\n",
    "test_mse = mean_squared_error(test_y, test_pred)\n",
    "\n",
    "test_rmse = np.sqrt(test_mse)\n",
    "\n",
    "print('Test RMSE: {}' .format(test_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Let's restrict the depth as well\n",
    "\n",
    "tree_reg2 = DecisionTreeRegressor(min_samples_leaf = 10, max_depth=5) # additional restriction on learning parameters\n",
    "\n",
    "tree_reg2.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train RMSE\n",
    "train_pred = tree_reg2.predict(train_x)\n",
    "\n",
    "train_mse = mean_squared_error(train_y, train_pred)\n",
    "\n",
    "train_rmse = np.sqrt(train_mse)\n",
    "\n",
    "print('Train RMSE: {}' .format(train_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test RMSE\n",
    "test_pred = tree_reg2.predict(test_x)\n",
    "\n",
    "test_mse = mean_squared_error(test_y, test_pred)\n",
    "\n",
    "test_rmse = np.sqrt(test_mse)\n",
    "\n",
    "print('Test RMSE: {}' .format(test_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(tree_reg2.feature_importances_,2) # what columns are important? only a few..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(125,50))\n",
    "\n",
    "tree = plot_tree(tree_reg2,\n",
    "                 #feature_names=train_inputs.columns.value, # our feature names are stripped form the data set\n",
    "                 #class_names=np.unique(train_y),\n",
    "                 filled=True,\n",
    "                 rounded=True,\n",
    "                 fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avoid Overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_error = []\n",
    "test_error = []\n",
    "\n",
    "for x in range(1,31):\n",
    "    tree_reg3 = DecisionTreeRegressor(max_depth=x)\n",
    "    tree_reg3.fit(train_x, train_y)\n",
    "    reg_train_predictions = tree_reg3.predict(train_x)\n",
    "    reg_test_predictions = tree_reg3.predict(test_x)\n",
    "    train_rmse = round(np.sqrt(mean_squared_error (train_y, reg_train_predictions)),4)\n",
    "    test_rmse = round(np.sqrt(mean_squared_error (test_y, reg_test_predictions)),4)\n",
    "    print('# Max depth = {}'.format(x) + \"     \" +'Train RMSE = {}'.format(train_rmse) + \"   \"\n",
    "         'Test RMSE = {}'.format(test_rmse))\n",
    "    \n",
    "    train_error.append(train_rmse)\n",
    "    test_error.append(test_rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_error, label='Train')\n",
    "plt.plot(test_error, label='Test')\n",
    "plt.xlabel(\"max Depth\")\n",
    "plt.ylabel(\"Error\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Randomized Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_grid = [\n",
    "    {'min_samples_leaf': np.arange(10, 30), \n",
    "     'max_depth': np.arange(10,30)}\n",
    "  ]\n",
    "\n",
    "tree_reg = DecisionTreeRegressor()\n",
    "\n",
    "grid_search = RandomizedSearchCV(tree_reg, param_grid, cv=5, n_iter=10,\n",
    "                           scoring='neg_mean_squared_error', verbose=1,\n",
    "                           return_train_score=True)\n",
    "\n",
    "grid_search.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvres = grid_search.cv_results_\n",
    "\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(np.sqrt(-mean_score), params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train RMSE\n",
    "train_pred = grid_search.best_estimator_.predict(train_x)\n",
    "\n",
    "train_mse = mean_squared_error(train_y, train_pred)\n",
    "\n",
    "train_rmse = np.sqrt(train_mse)\n",
    "\n",
    "print('Train RMSE: {}' .format(train_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test RMSE\n",
    "test_pred = grid_search.best_estimator_.predict(test_x)\n",
    "\n",
    "test_mse = mean_squared_error(test_y, test_pred)\n",
    "\n",
    "test_rmse = np.sqrt(test_mse)\n",
    "\n",
    "print('Test RMSE: {}' .format(test_rmse))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "nav_menu": {
   "height": "279px",
   "width": "309px"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
